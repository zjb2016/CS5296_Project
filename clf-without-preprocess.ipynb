{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a1063374",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T08:52:39.590357Z",
     "iopub.status.busy": "2022-04-18T08:52:39.590132Z",
     "iopub.status.idle": "2022-04-18T08:52:54.905453Z",
     "shell.execute_reply": "2022-04-18T08:52:54.904788Z",
     "shell.execute_reply.started": "2022-04-18T08:52:39.590333Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e92e23c259594cfc8d7e207cfee14e61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas==0.25.1\n",
      "  Downloading https://files.pythonhosted.org/packages/7e/ab/ea76361f9d3e732e114adcd801d2820d5319c23d0ac5482fa3b412db217e/pandas-0.25.1-cp37-cp37m-manylinux1_x86_64.whl (10.4MB)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/site-packages (from pandas==0.25.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib64/python3.7/site-packages (from pandas==0.25.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/site-packages (from pandas==0.25.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/site-packages (from python-dateutil>=2.6.1->pandas==0.25.1)\n",
      "Installing collected packages: pandas\n",
      "Successfully installed pandas-0.25.1\n",
      "\n",
      "You are using pip version 9.0.1, however version 22.0.4 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command."
     ]
    }
   ],
   "source": [
    "sc.install_pypi_package(\"pandas==0.25.1\")\n",
    "# sc.list_packages()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0926d835-f656-4a78-a42d-8b1d443ed199",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T03:35:20.022111Z",
     "iopub.status.busy": "2022-04-18T03:35:20.021892Z",
     "iopub.status.idle": "2022-04-18T03:35:41.835449Z",
     "shell.execute_reply": "2022-04-18T03:35:41.833347Z",
     "shell.execute_reply.started": "2022-04-18T03:35:20.022087Z"
    }
   },
   "source": [
    "## Read CSV File and Get DataFrame (pyspark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a9ddbdb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T08:16:35.458449Z",
     "iopub.status.busy": "2022-04-18T08:16:35.458226Z",
     "iopub.status.idle": "2022-04-18T08:16:37.749404Z",
     "shell.execute_reply": "2022-04-18T08:16:37.748795Z",
     "shell.execute_reply.started": "2022-04-18T08:16:35.458425Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a78e49277c54245bbeb14d6ae680161",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- content: string (nullable = true)\n",
      " |-- label: double (nullable = true)\n",
      "\n",
      "+--------------------+-----+\n",
      "|             content|label|\n",
      "+--------------------+-----+\n",
      "|Working with one ...|  0.0|\n",
      "|Well...tremors I,...|  0.0|\n",
      "|Ouch! This one wa...|  0.0|\n",
      "|I've seen some cr...|  0.0|\n",
      "|\"Carriers\" follow...|  0.0|\n",
      "|I had been lookin...|  0.0|\n",
      "|Effect(s) without...|  0.0|\n",
      "|This picture star...|  0.0|\n",
      "|I chose to see th...|  0.0|\n",
      "|This film has to ...|  0.0|\n",
      "|I felt brain dead...|  0.0|\n",
      "|A young scientist...|  0.0|\n",
      "|Inept, boring, an...|  0.0|\n",
      "|From the first ti...|  0.0|\n",
      "|I find it hard to...|  0.0|\n",
      "|I actually saw Ch...|  0.0|\n",
      "|I went to school ...|  0.0|\n",
      "|I haven't seen th...|  0.0|\n",
      "|I haven't seen an...|  0.0|\n",
      "|One would think t...|  0.0|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "import re\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "train_path = \"s3://myprojectsentiment/data/train.csv\"\n",
    "test_path = \"s3://myprojectsentiment/data/test.csv\"\n",
    "\n",
    "def readCSV(path):\n",
    "    df = (spark.read\n",
    "      .option(\"charset\", \"utf-8\")\n",
    "      .option(\"multiline\", \"true\")\n",
    "      .option(\"quote\", '\"')\n",
    "      .option(\"header\", \"true\")\n",
    "      .option(\"escape\", \"\\\\\")\n",
    "      .option(\"escape\", '\"')\n",
    "      .csv(path))\n",
    "    df = df.select([F.col(col).alias(re.sub(\"[^0-9a-zA-Z$]+\",\"\",col)) for col in df.columns])\n",
    "    df = df.withColumn('label', F.col('label').cast(DoubleType()))\n",
    "    return df\n",
    "\n",
    "train_df = readCSV(train_path)\n",
    "test_df = readCSV(test_path)\n",
    "\n",
    "train_df.printSchema()\n",
    "train_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba1b959-0b87-4ba6-8121-b72046dc2608",
   "metadata": {},
   "source": [
    "## Convert to TF IDF model\n",
    "\n",
    "- **Term-Frequency Inverse Document Frequency (TF-IDF)**\n",
    "  - some words are common among many documents\n",
    "    - common words are less informative because they appear in both classes.\n",
    "  - **inverse document frequency (IDF)** - measure rarity of each word\n",
    "    - $IDF(j) = \\log \\frac{N}{N_j}$\n",
    "      - $N$ is the number of documents.\n",
    "      - $N_j$ is the number of documents with word $j$.\n",
    "    - IDF is:\n",
    "      - 0 when a word is common to all documents\n",
    "      - large value when the word appears in few documents\n",
    "  - **TF-IDF vector:** downscale words that are common in many documents\n",
    "    - multiply TF and IDF terms\n",
    "    - $x_j = \\frac{w_j}{|D|} \\log \\frac{N}{N_j}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ef67d21-a1a9-4a87-b16f-63ea74aaf0c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T08:16:40.257273Z",
     "iopub.status.busy": "2022-04-18T08:16:40.256993Z",
     "iopub.status.idle": "2022-04-18T08:17:01.632126Z",
     "shell.execute_reply": "2022-04-18T08:17:01.631422Z",
     "shell.execute_reply.started": "2022-04-18T08:16:40.257242Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ced8b64778d466bbe22b8cce5ce9c83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|  0.0|(500,[3,14,17,64,...|\n",
      "|  0.0|(500,[3,5,7,8,10,...|\n",
      "|  0.0|(500,[0,7,8,11,17...|\n",
      "|  0.0|(500,[3,7,12,16,1...|\n",
      "|  0.0|(500,[0,10,11,12,...|\n",
      "|  0.0|(500,[1,3,8,16,17...|\n",
      "|  0.0|(500,[6,11,15,17,...|\n",
      "|  0.0|(500,[3,8,12,17,1...|\n",
      "|  0.0|(500,[0,7,10,14,1...|\n",
      "|  0.0|(500,[3,6,14,17,2...|\n",
      "|  0.0|(500,[1,3,4,5,17,...|\n",
      "|  0.0|(500,[2,3,17,22,2...|\n",
      "|  0.0|(500,[3,13,17,33,...|\n",
      "|  0.0|(500,[8,10,11,12,...|\n",
      "|  0.0|(500,[3,10,11,17,...|\n",
      "|  0.0|(500,[14,17,18,22...|\n",
      "|  0.0|(500,[0,12,17,24,...|\n",
      "|  0.0|(500,[3,8,17,24,2...|\n",
      "|  0.0|(500,[3,8,12,17,2...|\n",
      "|  0.0|(500,[3,10,11,12,...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
    "\n",
    "def converttf_idf(df, feature_num):\n",
    "    tokenizer = Tokenizer(inputCol=\"content\", outputCol=\"words\")\n",
    "    wordsData = tokenizer.transform(df)\n",
    "\n",
    "    hashingTF = HashingTF(inputCol=\"words\", outputCol=\"rawFeatures\", numFeatures=feature_num)\n",
    "    featurizedData = hashingTF.transform(wordsData)\n",
    "    # alternatively, CountVectorizer can also be used to get term frequency vectors\n",
    "\n",
    "    idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "    idfModel = idf.fit(featurizedData)\n",
    "    rescaledData = idfModel.transform(featurizedData)\n",
    "    return rescaledData\n",
    "\n",
    "tran_xtf = converttf_idf(train_df, 500)\n",
    "test_xtf = converttf_idf(test_df, 500)\n",
    "\n",
    "train = tran_xtf.select(\"label\", \"features\")\n",
    "test = test_xtf.select(\"label\", \"features\")\n",
    "\n",
    "train.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfed5bb-5471-4f4d-8e09-06142cae2e5f",
   "metadata": {},
   "source": [
    "## Naive Bayes Multinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ce85fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T08:17:01.633653Z",
     "iopub.status.busy": "2022-04-18T08:17:01.633402Z",
     "iopub.status.idle": "2022-04-18T08:17:20.987386Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e475c7e7ed1040ca915758b0a9aeb50e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|label|            features|       rawPrediction|         probability|prediction|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|  0.0|(500,[3,17,23,26,...|[-622.13189632295...|[0.21479398803266...|       1.0|\n",
      "|  0.0|(500,[2,17,32,35,...|[-639.74585979688...|[0.95308340974305...|       0.0|\n",
      "|  0.0|(500,[1,6,7,10,17...|[-1008.1710972640...|[0.86299582670018...|       0.0|\n",
      "|  0.0|(500,[0,3,7,10,11...|[-2724.6127297877...|[0.94078884648410...|       0.0|\n",
      "|  0.0|(500,[3,9,10,11,1...|[-1189.8561792820...|[0.06849454795089...|       1.0|\n",
      "|  0.0|(500,[3,4,8,17,26...|[-1035.7808488607...|[0.78948265063038...|       0.0|\n",
      "|  0.0|(500,[8,13,17,23,...|[-764.49258409310...|[0.98224276054769...|       0.0|\n",
      "|  0.0|(500,[17,18,22,27...|[-520.50285576704...|[0.20497001582073...|       1.0|\n",
      "|  0.0|(500,[0,2,10,13,1...|[-1685.8780175841...|[0.97722965807648...|       0.0|\n",
      "|  0.0|(500,[0,3,16,17,1...|[-1425.0379016050...|[0.91871022170786...|       0.0|\n",
      "|  0.0|(500,[0,10,17,23,...|[-694.23639481095...|[0.98951814860594...|       0.0|\n",
      "|  0.0|(500,[3,7,9,12,17...|[-779.11932531024...|[0.15308960936915...|       1.0|\n",
      "|  0.0|(500,[5,17,23,27,...|[-911.66219982708...|[0.65006884174700...|       0.0|\n",
      "|  0.0|(500,[0,3,4,6,7,1...|[-2106.7734270054...|[0.02571373036414...|       1.0|\n",
      "|  0.0|(500,[2,16,17,26,...|[-961.58390487965...|[0.99901303599487...|       0.0|\n",
      "|  0.0|(500,[5,10,17,18,...|[-445.16589656539...|[0.60605931591713...|       0.0|\n",
      "|  0.0|(500,[3,5,8,10,12...|[-1191.1983270726...|[0.99974219421793...|       0.0|\n",
      "|  0.0|(500,[6,12,16,17,...|[-1259.8779832530...|[0.99989417309033...|       0.0|\n",
      "|  0.0|(500,[0,1,3,7,9,1...|[-1502.4670964070...|[0.99802623484963...|       0.0|\n",
      "|  0.0|(500,[3,17,23,26,...|[-799.79111415837...|[0.21456243630273...|       1.0|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Test set accuracy = 0.7274"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# create the trainer and set its parameters\n",
    "nb = NaiveBayes(smoothing=1.0, modelType=\"multinomial\")\n",
    "\n",
    "# train the model\n",
    "model = nb.fit(train)\n",
    "\n",
    "# select example rows to display.\n",
    "predictions = model.transform(test)\n",
    "predictions.show()\n",
    "\n",
    "# compute accuracy on the test set\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\",\n",
    "                                              metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test set accuracy = \" + str(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744505e5-22e5-4266-b2c5-fe5c87ea069a",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c18cf0b7-08cd-4d75-9869-c6513cc73c9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T09:20:47.048590Z",
     "iopub.status.busy": "2022-04-18T09:20:47.048270Z",
     "iopub.status.idle": "2022-04-18T09:21:22.472703Z",
     "shell.execute_reply": "2022-04-18T09:21:22.472018Z",
     "shell.execute_reply.started": "2022-04-18T09:20:47.048553Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43ef7004c0364c85ad133c33eefb210b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|label|            features|       rawPrediction|         probability|prediction|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|  0.0|(500,[3,17,23,26,...|[-0.7165276591984...|[0.32815807383877...|       1.0|\n",
      "|  0.0|(500,[2,17,32,35,...|[2.15321023530749...|[0.89596838042190...|       0.0|\n",
      "|  0.0|(500,[1,6,7,10,17...|[1.80688427705520...|[0.85898488917680...|       0.0|\n",
      "|  0.0|(500,[0,3,7,10,11...|[5.09146906636550...|[0.99388859889409...|       0.0|\n",
      "|  0.0|(500,[3,9,10,11,1...|[-1.6907287047053...|[0.15568003240277...|       1.0|\n",
      "|  0.0|(500,[3,4,8,17,26...|[-0.8380469483374...|[0.30194627862082...|       1.0|\n",
      "|  0.0|(500,[8,13,17,23,...|[2.56740341310094...|[0.92873402647590...|       0.0|\n",
      "|  0.0|(500,[17,18,22,27...|[-0.3371114133701...|[0.41651131948666...|       1.0|\n",
      "|  0.0|(500,[0,2,10,13,1...|[1.09957381600853...|[0.75018024303529...|       0.0|\n",
      "|  0.0|(500,[0,3,16,17,1...|[-0.1367084115375...|[0.46587602635376...|       1.0|\n",
      "|  0.0|(500,[0,10,17,23,...|[3.14604767869691...|[0.95875270656247...|       0.0|\n",
      "|  0.0|(500,[3,7,9,12,17...|[-0.5420938916390...|[0.36770062428138...|       1.0|\n",
      "|  0.0|(500,[5,17,23,27,...|[0.44092065680566...|[0.60847838295563...|       0.0|\n",
      "|  0.0|(500,[0,3,4,6,7,1...|[1.09326545489137...|[0.74899612917586...|       0.0|\n",
      "|  0.0|(500,[2,16,17,26,...|[2.37353935605720...|[0.91478716440955...|       0.0|\n",
      "|  0.0|(500,[5,10,17,18,...|[-0.5879691362110...|[0.35710096431204...|       1.0|\n",
      "|  0.0|(500,[3,5,8,10,12...|[3.25875948129122...|[0.96298659977476...|       0.0|\n",
      "|  0.0|(500,[6,12,16,17,...|[3.65838606894672...|[0.97487353468624...|       0.0|\n",
      "|  0.0|(500,[0,1,3,7,9,1...|[2.11661622215987...|[0.89250772860743...|       0.0|\n",
      "|  0.0|(500,[3,17,23,26,...|[0.05096872305277...|[0.51273942299844...|       0.0|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Test set accuracy = 0.75944"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.sql import Row\n",
    "from pyspark.ml.linalg import Vectors\n",
    "\n",
    "# build model and fit\n",
    "lr = LogisticRegression(maxIter=10)\n",
    "lrModel = lr.fit(train)\n",
    "\n",
    "# select example rows to display.\n",
    "predictions = lrModel.transform(test)\n",
    "predictions.show()\n",
    "\n",
    "# compute accuracy on the test set\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\",\n",
    "                                              metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test set accuracy = \" + str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8844aaef-14e5-4159-90f8-8e2f3b58d610",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T07:36:54.624608Z",
     "iopub.status.busy": "2022-04-18T07:36:54.624360Z",
     "iopub.status.idle": "2022-04-18T07:37:03.959051Z",
     "shell.execute_reply": "2022-04-18T07:37:03.958325Z",
     "shell.execute_reply.started": "2022-04-18T07:36:54.624575Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f20ca71f5b2463da54d6a9e2228d681",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objectiveHistory:\n",
      "0.6931471805599471\n",
      "+---+---+\n",
      "|FPR|TPR|\n",
      "+---+---+\n",
      "|0.0|0.0|\n",
      "|1.0|1.0|\n",
      "|1.0|1.0|\n",
      "+---+---+\n",
      "\n",
      "areaUnderROC: 0.5\n",
      "LogisticRegression_77a1159abbdd"
     ]
    }
   ],
   "source": [
    "# Extract the summary from the returned LogisticRegressionModel instance trained\n",
    "# in the earlier example\n",
    "trainingSummary = lrModel.summary\n",
    "\n",
    "# Obtain the objective per iteration\n",
    "objectiveHistory = trainingSummary.objectiveHistory\n",
    "print(\"objectiveHistory:\")\n",
    "for objective in objectiveHistory:\n",
    "    print(objective)\n",
    "\n",
    "# Obtain the receiver-operating characteristic as a dataframe and areaUnderROC.\n",
    "trainingSummary.roc.show()\n",
    "print(\"areaUnderROC: \" + str(trainingSummary.areaUnderROC))\n",
    "\n",
    "# Set the model threshold to maximize F-Measure\n",
    "fMeasure = trainingSummary.fMeasureByThreshold\n",
    "maxFMeasure = fMeasure.groupBy().max('F-Measure').select('max(F-Measure)').head()\n",
    "bestThreshold = fMeasure.where(fMeasure['F-Measure'] == maxFMeasure['max(F-Measure)']) \\\n",
    "    .select('threshold').head()['threshold']\n",
    "lr.setThreshold(bestThreshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b545b350-8b00-47de-92b2-24429868cf25",
   "metadata": {},
   "source": [
    "## Logistic Regression with Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f06f61f-efdd-4089-9ac3-e78fd56b56c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T13:04:19.843738Z",
     "iopub.status.busy": "2022-04-18T13:04:19.843379Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca62b2d1002443e1ad5a7d76a1ddd6ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+----------+\n",
      "|             content|label|prediction|\n",
      "+--------------------+-----+----------+\n",
      "|Alan Rickman & Em...|  0.0|       1.0|\n",
      "|I have seen this ...|  0.0|       1.0|\n",
      "|In Los Angeles, t...|  0.0|       0.0|\n",
      "|This film is bund...|  0.0|       0.0|\n",
      "|I only comment on...|  0.0|       1.0|\n",
      "|When you look at ...|  0.0|       0.0|\n",
      "|Rollerskating vam...|  0.0|       0.0|\n",
      "|Technically abomi...|  0.0|       1.0|\n",
      "|When Hollywood is...|  0.0|       0.0|\n",
      "|Respected western...|  0.0|       1.0|\n",
      "|Worst movie ever ...|  0.0|       0.0|\n",
      "|I was forced to w...|  0.0|       1.0|\n",
      "|Well it is about ...|  0.0|       0.0|\n",
      "|Man with the Scre...|  0.0|       1.0|\n",
      "|I never read the ...|  0.0|       0.0|\n",
      "|One of the movies...|  0.0|       1.0|\n",
      "|Well I had the ch...|  0.0|       0.0|\n",
      "|This is a movie t...|  0.0|       0.0|\n",
      "|Dark Harvest is a...|  0.0|       0.0|\n",
      "|A handful of nubi...|  0.0|       0.0|\n",
      "+--------------------+-----+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Test set accuracy = 0.79984"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.feature import HashingTF, Tokenizer\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "\n",
    "# Configure an ML pipeline, which consists of tree stages: tokenizer, hashingTF, and lr.\n",
    "tokenizer = Tokenizer(inputCol=\"content\", outputCol=\"words\")\n",
    "hashingTF = HashingTF(inputCol=tokenizer.getOutputCol(), outputCol=\"rawfeatures\")\n",
    "idf = IDF(inputCol=hashingTF.getOutputCol(), outputCol=\"features\")\n",
    "\n",
    "lr = LogisticRegression(maxIter=10)\n",
    "pipeline = Pipeline(stages=[tokenizer, hashingTF,idf, lr])\n",
    "\n",
    "\n",
    "# this grid will have 3*3 = 9 parameter settings for CrossValidator to choose from.\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(hashingTF.numFeatures, [200, 800, 1600]) \\\n",
    "    .addGrid(lr.regParam, [0.1, 0.05, 0.01]) \\\n",
    "    .build()\n",
    "\n",
    "crossval = CrossValidator(estimator=pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=BinaryClassificationEvaluator(),\n",
    "                          numFolds=4)  # use 3+ folds in practice\n",
    "\n",
    "# Run cross-validation, and choose the best set of parameters.\n",
    "cvModel = crossval.fit(train_df)\n",
    "\n",
    "# Make predictions on test documents. cvModel uses the best model found (lrModel).\n",
    "prediction = cvModel.transform(test_df)\n",
    "selected = prediction.select( \"content\", \"label\", \"prediction\")\n",
    "selected.show()\n",
    "\n",
    "# compute accuracy on the test set\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"label\", rawPredictionCol=\"prediction\")\n",
    "accuracy = evaluator.evaluate(selected)\n",
    "print(\"Test set accuracy = \" + str(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3bba3e-246b-43e1-bb06-8c9dae075da6",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8ca3fdf-770b-4bfb-91d0-412830d86790",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T07:37:03.960198Z",
     "iopub.status.busy": "2022-04-18T07:37:03.960029Z",
     "iopub.status.idle": "2022-04-18T07:37:49.500550Z",
     "shell.execute_reply": "2022-04-18T07:37:49.499936Z",
     "shell.execute_reply.started": "2022-04-18T07:37:03.960177Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d124ab68aea45f88f407d39ed7f69d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+--------------------+\n",
      "|predictedLabel|label|            features|\n",
      "+--------------+-----+--------------------+\n",
      "|           1.0|  0.0|(500,[3,17,23,26,...|\n",
      "|           0.0|  0.0|(500,[2,17,32,35,...|\n",
      "|           1.0|  0.0|(500,[1,6,7,10,17...|\n",
      "|           0.0|  0.0|(500,[0,3,7,10,11...|\n",
      "|           1.0|  0.0|(500,[3,9,10,11,1...|\n",
      "+--------------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "accuracy = 0.67364\n",
      "RandomForestClassificationModel: uid=RandomForestClassifier_f7add8a63034, numTrees=20, numClasses=2, numFeatures=500"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "\n",
    "labelIndexer = StringIndexer(inputCol=\"label\", outputCol=\"indexedLabel\").fit(train)\n",
    "featureIndexer = VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4).fit(train)\n",
    "\n",
    "# Train a RandomForest model.\n",
    "rf = RandomForestClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\", numTrees=20)\n",
    "\n",
    "# Convert indexed labels back to original labels.\n",
    "labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\",\n",
    "                               labels=labelIndexer.labels)\n",
    "\n",
    "# Chain indexers and forest in a Pipeline\n",
    "pipeline = Pipeline(stages=[labelIndexer, featureIndexer, rf, labelConverter])\n",
    "\n",
    "# Train model.  This also runs the indexers.\n",
    "model = pipeline.fit(train)\n",
    "\n",
    "# Make predictions.\n",
    "predictions = model.transform(test)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions.select(\"predictedLabel\", \"label\", \"features\").show(5)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"accuracy = %g\" % (accuracy))\n",
    "\n",
    "rfModel = model.stages[2]\n",
    "print(rfModel)  # summary only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631f098f-c529-4a25-b498-304b435b5b38",
   "metadata": {},
   "source": [
    "## Multilayer perceptron classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f184a292-0404-462a-9f2e-2af37125c54e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T07:42:23.517080Z",
     "iopub.status.busy": "2022-04-18T07:42:23.516854Z",
     "iopub.status.idle": "2022-04-18T07:55:01.295533Z",
     "shell.execute_reply": "2022-04-18T07:55:01.294864Z",
     "shell.execute_reply.started": "2022-04-18T07:42:23.517058Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47eb4cebc65d48d39a153494983f9d1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy = 0.72296"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "\n",
    "# specify layers for the neural network:\n",
    "# input layer of size 500 (features), four intermediate layer\n",
    "# and output of size 2 (classes)\n",
    "layers = [500, 128, 32, 8, 2]\n",
    "\n",
    "# create the trainer and set its parameters\n",
    "trainer = MultilayerPerceptronClassifier(maxIter=100, layers=layers, blockSize=128, seed=1234)\n",
    "\n",
    "# train the model\n",
    "model = trainer.fit(train)\n",
    "\n",
    "# compute accuracy on the test set\n",
    "result = model.transform(test)\n",
    "\n",
    "predictionAndLabels = result.select(\"prediction\", \"label\")\n",
    "evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
    "print(\"Test set accuracy = \" + str(evaluator.evaluate(predictionAndLabels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56cdf5d",
   "metadata": {},
   "source": [
    "## Save Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "86b3fffe-b509-4a63-89cc-0d48241bc9e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T09:15:47.671140Z",
     "iopub.status.busy": "2022-04-18T09:15:47.670910Z",
     "iopub.status.idle": "2022-04-18T09:15:47.722529Z",
     "shell.execute_reply": "2022-04-18T09:15:47.721969Z",
     "shell.execute_reply.started": "2022-04-18T09:15:47.671117Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc148eff3dd8483d8e537dfd721f0e2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "# write prediction file with timestamp file name\n",
    "def savePrediction(lines, path):\n",
    "    to_day = datetime.datetime.today()\n",
    "    to_day = str(to_day)[0:19]\n",
    "    to_day = re.sub(\"[^0-9a-zA-Z$]+\",\"_\",to_day)\n",
    "    file_path = path + to_day\n",
    "    file_path.strip()\n",
    "    lines.coalesce(1).write.csv(file_path, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0ebeee01-ea54-423a-8f62-d3b8f24fec2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T09:15:50.550145Z",
     "iopub.status.busy": "2022-04-18T09:15:50.549846Z",
     "iopub.status.idle": "2022-04-18T09:16:30.126764Z",
     "shell.execute_reply": "2022-04-18T09:16:30.126187Z",
     "shell.execute_reply.started": "2022-04-18T09:15:50.550118Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5968da3c9c6f46cbb49b5947ad68edd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_df = (spark.read\n",
    "      .option(\"charset\", \"utf-8\")\n",
    "      .option(\"header\", \"true\")\n",
    "      .csv(test_path))\n",
    "\n",
    "pdf = test_df.toPandas()\n",
    "pred = predictions.toPandas()\n",
    "pdf['predictedLabel'] = pred['prediction']\n",
    "sdf = spark.createDataFrame(pdf)\n",
    "\n",
    "savePrediction(sdf,'s3://janev/output/project/')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
